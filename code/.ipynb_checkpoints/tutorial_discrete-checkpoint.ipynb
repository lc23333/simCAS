{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a370949-c11d-4596-8181-dd639730bccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from simCAS import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f621ffb-9499-4502-9da2-f86ec7564dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import multivariate_normal\n",
    "import rpy2\n",
    "import rpy2.robjects as robjects\n",
    "from rpy2.robjects.packages import importr\n",
    "import pandas as pd\n",
    "from sklearn.neighbors import KernelDensity\n",
    "import os\n",
    "from scipy import sparse\n",
    "import scipy.io as sio\n",
    "import scanpy as sc\n",
    "from Bio import Phylo\n",
    "from io import StringIO\n",
    "import logging\n",
    "from scipy.optimize import fsolve\n",
    "import random\n",
    "import threading\n",
    "import scipy.stats as stats\n",
    "from sklearn.mixture import GaussianMixture as GMM\n",
    "from scipy.stats import logser\n",
    "\n",
    "from scipy.special import rel_entr\n",
    "from statsmodels.discrete.count_model import (ZeroInflatedNegativeBinomialP, ZeroInflatedPoisson,\n",
    "                                              ZeroInflatedGeneralizedPoisson)\n",
    "import statsmodels.api as sm\n",
    "from scipy.stats import nbinom\n",
    "from scipy.special import expit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "19089f04-5f15-4585-94f3-c8c0900ed665",
   "metadata": {},
   "outputs": [],
   "source": [
    "#读取参数\n",
    "prefix_='Buenrostro_2018'\n",
    "# prefix_='Forebrain'\n",
    "# prefix_='MCA/Cerebellum'\n",
    "resultdir='/data1/lichen/code/second/scATAC_integration/data/scATACdata_total/process/{0}/'.format(prefix_)\n",
    "peak_mean=pd.read_csv(resultdir+'peak_mean_log.csv',index_col=0)\n",
    "lib_size=pd.read_csv(resultdir+'library_size_log.csv',index_col=0)\n",
    "nozero=pd.read_csv(resultdir+'nozero_log.csv',index_col=0)\n",
    "\n",
    "peak_mean=np.array(peak_mean['peak mean'])\n",
    "lib_size=np.array(lib_size['library size'])\n",
    "nozero=np.array(nozero['nozero'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d1ead269-aabb-43bf-95b0-2bb1da6d66cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置参数，后续所有函数中的参数都在下面给出定义\n",
    "\n",
    "n_peak         =len(peak_mean) # peak数目\n",
    "n_cell_total   =1500 #总共的细胞数目\n",
    "rand_seed      =2022 #随机种子\n",
    "zero_prob      =0.5  #对于peak_effect的置零个数\n",
    "zero_set       ='all'#'by_row'指的是对于每一个peak的effect vector进行置零；'all'指的是随机在所有的index中选择进行置零\n",
    "effect_mean    =0 #生成effect vector的均值\n",
    "effect_sd      =1 #生成effect vector的方差\n",
    "\n",
    "min_popsize    =300 #离散模式下设定的细胞群的最小数目\n",
    "min_pop        ='A' #离散模式下设定最小细胞群的名称，注意需要与下面的tree_text一致\n",
    "tree_text      =[\"((A:1,B:1):1,(C:1,D:1):1);\", #注：前三个用来仿真离散模式，只标叶子结点名称就行；后两个为连续模式的仿真树，与标准newick形式略有不同\n",
    "                 \"(A:1,(C:1,D:1):1);\",\n",
    "                '(((A:1, B:1):1,(C:0.2, D:0.2):1):1, E:3);',\n",
    "                '((((A:1, B:1)C:1,(D:0.2, E:0.2)F:1)G:1, H:3)S)',\n",
    "                \"(((A:1,B:1)C:1,(D:1,E:1)F:1)S)\"]\n",
    "pops_name      =[['A','B','C','D'],\n",
    "                ['A','C','D'],\n",
    "                ['A','B','C','D','E']]  # 输入不同节点的名字，离散模式只需要输入叶子节点的名称就行，注意这里需要与tree_text的前三个顺序保持一致\n",
    "pops_size      =None # 设置不同cluster的细胞数目，None则直接取平均\n",
    "\n",
    "\n",
    "embed_mean_same=1 # 对embedding非差异特征采样的均值\n",
    "embed_sd_same  =0.5 # 对embedding的非差异特征采样的方差\n",
    "embed_mean_diff=1 # 对embedding差异特征采样的均值\n",
    "embed_sd_diff  =0.5 # 对embedding的差异特征采样的方差\n",
    "\n",
    "len_cell_embed =12   #仿真细胞的低维特征的特征个数\n",
    "n_embed_diff   =10 # 使得cell embedding不同的特征维度数目\n",
    "n_embed_same   =len_cell_embed-n_embed_diff\n",
    "\n",
    "simu_type      ='discrete' # continuous/discrete/single/cell_type\n",
    "correct_iter   =2 # 使用参数进行修正的迭代次数\n",
    "activation     ='exp_linear' #对参数矩阵矫正的方式，在连续和离散的条件下使用'exp'，在仿真celltype的时候应该使用'sigmod'\n",
    "\n",
    "two_embeds     =True  # true表明peak mean和library size通过两个不同的矩阵排序对应得到；False 表明通过一个矩阵的值排序对应得到\n",
    "\n",
    "adata_dir      =resultdir+'adata_forsimulation.h5ad' # 为了进行cell_type simulation\n",
    "lib_simu       ='estimate' # 在仿真cell_type时用的参数，’real‘表示直接使用真实的library_size参数，‘estimate’表示从估计的分布中采样\n",
    "distribution   ='Poisson' # 数据的分布，如果二值化就是’Bernoulli‘，count就是‘Poisson’\n",
    "\n",
    "bw_pm          =1e-4 #分别为对peak mean、library_size、nozero的核密度估计的窗宽；注：bw_pm若取的过大可能会导致采样的peak mean小于0而报错\n",
    "bw_lib         =0.05\n",
    "bw_nozero      =0.05\n",
    "\n",
    "real_param     =False # 是否使用真实的参数，True则为直接使用真实参数，False\n",
    "\n",
    "log            =None\n",
    "\n",
    "fix_seed(rand_seed)\n",
    "\n",
    "k_dict,pi_dict={},{}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ababcc9a-9b77-4d50-a33a-d530bbf1e966",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**********start generate effect vector...**********\n",
      "**********generate effect finished!**********\n",
      "**********start generate cell embedding...**********\n",
      "simulation type is discrete\n",
      "**********generate cell embedding finished**********\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'peak_effect' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [5]\u001b[0m, in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m**********generate cell embedding finished**********\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;66;03m# 获得count\u001b[39;00m\n\u001b[0;32m---> 26\u001b[0m     atac_counts\u001b[38;5;241m=\u001b[39m\u001b[43mGet_Tree_Counts\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpeak_mean\u001b[49m\u001b[43m,\u001b[49m\u001b[43mlib_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43mnozero\u001b[49m\u001b[43m,\u001b[49m\u001b[43mn_peak\u001b[49m\u001b[43m,\u001b[49m\u001b[43mn_cell_total\u001b[49m\u001b[43m,\u001b[49m\u001b[43mrand_seed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m                    \u001b[49m\u001b[43membeds_peak\u001b[49m\u001b[43m,\u001b[49m\u001b[43membeds_lib\u001b[49m\u001b[43m,\u001b[49m\u001b[43mcorrect_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdistribution\u001b[49m\u001b[43m,\u001b[49m\u001b[43mactivation\u001b[49m\u001b[43m,\u001b[49m\u001b[43mbw_pm\u001b[49m\u001b[43m,\u001b[49m\u001b[43mbw_lib\u001b[49m\u001b[43m,\u001b[49m\u001b[43mbw_nozero\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m                                \u001b[49m\u001b[43mreal_param\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     29\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m**********generate counts finshed!**********\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m simu_type\u001b[38;5;241m==\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontinuous\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "File \u001b[0;32m/data1/lichen/code/second/scATAC_integration/code/simulation/simCAS/code/simCAS.py:546\u001b[0m, in \u001b[0;36mGet_Tree_Counts\u001b[0;34m(peak_mean, lib_size, nozero, n_peak, n_cell_total, rand_seed, embeds_peak, embeds_lib, correct_iter, distribution, activation, bw_pm, bw_lib, bw_nozero, real_param)\u001b[0m\n\u001b[1;32m    485\u001b[0m         param_nozero\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39msort(param_nozero,axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mravel()\n\u001b[1;32m    489\u001b[0m \u001b[38;5;66;03m#         estimation_dis='one_logser' # 'NB'/'one_logser'/'gamma'/'zero_logser'\u001b[39;00m\n\u001b[1;32m    490\u001b[0m         \n\u001b[1;32m    491\u001b[0m \u001b[38;5;66;03m#         print('the estimation method is ',estimation_dis)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    544\u001b[0m \n\u001b[1;32m    545\u001b[0m     \u001b[38;5;66;03m# 从模拟矩阵的参数顺序对应到采样的真实参数\u001b[39;00m\n\u001b[0;32m--> 546\u001b[0m     X_peak\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mdot(\u001b[43mpeak_effect\u001b[49m,embeds_peak)\u001b[38;5;66;03m# peak*cell\u001b[39;00m\n\u001b[1;32m    547\u001b[0m     X_peak\u001b[38;5;241m=\u001b[39mActivation(X_peak,method\u001b[38;5;241m=\u001b[39mactivation) \u001b[38;5;66;03m# 防止出现负值\u001b[39;00m\n\u001b[1;32m    548\u001b[0m     rank\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;28mlen\u001b[39m(X_peak))[np\u001b[38;5;241m.\u001b[39mmean(X_peak,axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39margsort()\u001b[38;5;241m.\u001b[39margsort()]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'peak_effect' is not defined"
     ]
    }
   ],
   "source": [
    "# 生成effect和embedding\n",
    "print(\"**********start generate effect vector...**********\")\n",
    "peak_effect,lib_size_effect=Get_Effect(n_peak,n_cell_total,\n",
    "                len_cell_embed,rand_seed,zero_prob,zero_set,effect_mean,effect_sd)\n",
    "print(\"**********generate effect finished!**********\")\n",
    "\n",
    "\n",
    "\n",
    "print(\"**********start generate cell embedding...**********\")\n",
    "print(\"simulation type is {0}\".format(simu_type))\n",
    "if simu_type=='discrete':\n",
    "    # 重复两次获得两个矩阵，后续使用参数two_embeds决定是用两个矩阵还是用一个\n",
    "    embeds_peak,meta=Get_Discrete_Embedding(pops_name[2],min_popsize,tree_text[2],\n",
    "                 n_cell_total,pops_size,\n",
    "                 embed_mean_same,embed_sd_same,\n",
    "                  embed_mean_diff,embed_sd_diff,\n",
    "                 n_embed_diff,n_embed_same,rand_seed,min_pop)\n",
    "    embeds_lib,meta=Get_Discrete_Embedding(pops_name[2],min_popsize,tree_text[2],\n",
    "                 n_cell_total,pops_size,\n",
    "                 embed_mean_same,embed_sd_same,\n",
    "                  embed_mean_diff,embed_sd_diff,\n",
    "                 n_embed_diff,n_embed_same,rand_seed+1,min_pop)\n",
    "    embeds_peak,embeds_lib=embeds_peak.values,embeds_lib.values\n",
    "    print(\"**********generate cell embedding finished**********\")\n",
    "    # 获得count\n",
    "    atac_counts=Get_Tree_Counts(peak_mean,lib_size,nozero,n_peak,n_cell_total,rand_seed,peak_effect,lib_size_effect,\n",
    "                    embeds_peak,embeds_lib,correct_iter,distribution,activation,bw_pm,bw_lib,bw_nozero,\n",
    "                                real_param)\n",
    "    print(\"**********generate counts finshed!**********\")\n",
    "    \n",
    "elif simu_type=='continuous':\n",
    "    embeds_param={}\n",
    "    embeds_peak,meta=Get_Continuous_Embedding(tree_text[4],n_cell_total,\n",
    "                 embed_mean_same,embed_sd_same,\n",
    "                  embed_mean_diff,embed_sd_diff,\n",
    "                 n_embed_diff,n_embed_same,rand_seed)\n",
    "    embeds_lib,meta=Get_Continuous_Embedding(tree_text[4],n_cell_total,\n",
    "                 embed_mean_same,embed_sd_same,\n",
    "                  embed_mean_diff,embed_sd_diff,\n",
    "                 n_embed_diff,n_embed_same,rand_seed+1)\n",
    "    embeds_peak,embeds_lib=embeds_peak.values,embeds_lib.values\n",
    "    print(\"**********generate cell embedding finished**********\")\n",
    "    \n",
    "    print(\"**********start generate counts...**********\")\n",
    "    atac_counts=Get_Tree_Counts(peak_mean,lib_size,nozero,n_peak,n_cell_total,rand_seed,peak_effect,lib_size_effect,\n",
    "                    embeds_peak,embeds_lib,correct_iter,distribution,activation,bw_pm,bw_lib,bw_nozero,\n",
    "                               real_param)\n",
    "    print(\"**********generate counts finshed!**********\")\n",
    "    \n",
    "elif simu_type=='single':\n",
    "    embeds_param={}\n",
    "    embeds_peak,meta=Get_Single_Embedding(n_cell_total,embed_mean_same,embed_sd_same,\n",
    "                 n_embed_diff,n_embed_same)\n",
    "    embeds_lib,meta=Get_Single_Embedding(n_cell_total,embed_mean_same,embed_sd_same,\n",
    "                 n_embed_diff,n_embed_same)\n",
    "    embeds_peak,embeds_lib=embeds_peak.values,embeds_lib.values\n",
    "    print(\"**********generate cell embedding finished!**********\")\n",
    "    \n",
    "    \n",
    "    print(\"**********start generate counts...**********\")\n",
    "    atac_counts=Get_Tree_Counts(peak_mean,lib_size,nozero,n_peak,n_cell_total,rand_seed,\n",
    "                    embeds_peak,embeds_lib,correct_iter,distribution,activation,bw_pm,bw_lib,bw_nozero)\n",
    "    print(\"**********generate counts finshed!**********\")\n",
    "    \n",
    "elif simu_type=='cell_type':\n",
    "    adata=sc.read_h5ad(adata_dir)\n",
    "    counts_list,celltype_list,embed_peak_list,embed_lib_list=[],[],[],[]\n",
    "    lambdas_list,simu_param_nozero_list,simu_param_lib_list,simu_param_pm_list=[],[],[],[]#新加的list用来重新对lambdas进行spasity的修正\n",
    "    celltypes=np.unique(adata.obs.celltype)\n",
    "    for i in range(len(celltypes)):\n",
    "    # 可以分为直接从真实数据中进行采样或是从核密度估计中采样特定细胞数目，先做直接从真实数据中采样的结果\n",
    "        # print(celltypes[i])\n",
    "        print(\"simulating cell type: {}...\".format(celltypes[i]))\n",
    "        adata_part=adata[adata.obs.celltype==celltypes[i],:]\n",
    "\n",
    "        # 对每个celltype单独进行仿真\n",
    "        counts,embed_peak,embed_lib,lambdas,simu_param_nozero,simu_param_lib,simu_param_pm=Get_Celltype_Counts(adata_part,two_embeds,\n",
    "                                            embed_mean_same,embed_sd_same,len_cell_embed,effect_mean,effect_sd,\n",
    "                     n_embed_diff,n_embed_same,correct_iter,lib_simu=lib_simu,n_cell_total=None,\n",
    "                                        distribution=distribution,activation=activation,\n",
    "                    bw_pm=bw_pm,bw_lib=bw_lib,bw_nozero=bw_nozero,rand_seed=rand_seed,zero_prob=zero_prob,zero_set=zero_set) # peak*cell\n",
    "\n",
    "        counts_list.append(counts)\n",
    "        embed_peak_list.append(embed_peak)\n",
    "        embed_lib_list.append(embed_lib)\n",
    "        celltype_list.append([celltypes[i]]*counts.shape[1])\n",
    "        lambdas_list.append(lambdas)\n",
    "        simu_param_nozero_list.append(simu_param_nozero)\n",
    "        simu_param_lib_list.append(simu_param_lib)\n",
    "        simu_param_pm_list.append(simu_param_pm)\n",
    "        \n",
    "    if distribution=='Poisson':\n",
    "        # atac_counts=np.hstack(counts_list)\n",
    "        meta=np.hstack(celltype_list)\n",
    "        embeds_peak=np.hstack(embed_peak_list)\n",
    "        embeds_lib=np.hstack(embed_lib_list)\n",
    "        #对整体lambdas进行sparsity修正\n",
    "        lambdas=np.hstack(lambdas_list)\n",
    "        simu_param_nozero=np.hstack(simu_param_nozero_list)\n",
    "        simu_param_lib=np.hstack(simu_param_lib_list)\n",
    "        simu_param_pm=peak_mean\n",
    "\n",
    "        lambdas_sum=np.sum(lambdas,axis=0)\n",
    "        \n",
    "        \n",
    "        n_cell_total=len(simu_param_lib)\n",
    "        print(\"**********start ZIP correction...**********\")\n",
    "        k_list,pi_list=[],[]\n",
    "        # 求解每个cell中lambda扩大的倍数和置零的比例\n",
    "        for i in range(n_cell_total):\n",
    "            iter_=i\n",
    "            # print(i)\n",
    "            def solve_function(unsolved_value):\n",
    "                k,pi=unsolved_value[0],unsolved_value[1]\n",
    "                return [\n",
    "                    k*(1-pi)-simu_param_lib[iter_]/(lambdas_sum[iter_]),\n",
    "                    n_peak*pi+(1-pi)*np.sum(np.exp(-lambdas[:,iter_]*k))-(n_peak-simu_param_nozero[iter_])\n",
    "                ]\n",
    "\n",
    "            solved=fsolve(solve_function,[3,0.5],maxfev=2000)\n",
    "            k,pi=solved[0],solved[1]\n",
    "            simu1=k*(1-pi)*(lambdas_sum[iter_])\n",
    "            real1=simu_param_lib[iter_]\n",
    "            if abs(simu1-real1)/real1>0.1:\n",
    "                print('=================================')\n",
    "                print(i)\n",
    "                print(simu1,real1)\n",
    "                solved=fsolve(solve_function,[20,0.5],maxfev=2000)\n",
    "            k,pi=solved[0],solved[1]\n",
    "            simu1=k*(1-pi)*(lambdas_sum[iter_])\n",
    "            real1=simu_param_lib[iter_]\n",
    "            if abs(simu1-real1)/real1>0.1:\n",
    "                print(i)\n",
    "                print(simu1,real1)\n",
    "                print('=================================')\n",
    "            k_list.append(solved[0])\n",
    "            pi_list.append(solved[1])\n",
    "        # 对每个cell的lambda置零并扩大相应倍数\n",
    "        for i in range(n_cell_total):\n",
    "            if k_list[i]==3 or k_list[i]==20 or pi_list[i]<0 or k_list[i]<0:\n",
    "                continue\n",
    "            a=lambdas[:,i]*k_list[i]\n",
    "            # b=atac_counts[:,i]\n",
    "            a[np.random.choice(n_peak,replace=False,size=int(pi_list[i]*n_peak))]=0\n",
    "            lambdas[:,i]=a\n",
    "        print(\"**********ZIP correction finished!**********\")\n",
    "        \n",
    "#         n_cell_total=len(simu_param_lib)\n",
    "#         print(\"**********start ZIP correction...**********\")\n",
    "#         batch_size = 1000 # 并行数目，全局字典\n",
    "#         global k_dict,pi_dict\n",
    "#         for i in range(0,n_cell_total,batch_size):\n",
    "#             if i+batch_size<=n_cell_total:\n",
    "#                 my_thread = [zip_correction_thread(j,simu_param_lib[j],lambdas[:,j],lambdas_sum[j],simu_param_nozero[j],n_peak) for j in range(i, i+batch_size)]\n",
    "#             else:\n",
    "#                 my_thread = [zip_correction_thread(j,simu_param_lib[j],lambdas[:,j],lambdas_sum[j],simu_param_nozero[j],n_peak) for j in range(i, n_cell_total)]\n",
    "#             for thread_ in my_thread:\n",
    "#                 thread_.start()\n",
    "#             for thread_ in my_thread:\n",
    "#                 thread_.join()\n",
    "#         # 对每个cell的lambda置零并扩大相应倍数\n",
    "#         for i in range(n_cell_total):\n",
    "#             if k_dict[i]==3 or k_dict[i]==20 or pi_dict[i]<0 or k_dict[i]<0:\n",
    "#                 continue\n",
    "#             a=lambdas[:,i]*k_dict[i]\n",
    "#             # b=atac_counts[:,i]\n",
    "#             a[np.random.choice(n_peak,replace=False,size=int(pi_dict[i]*n_peak))]=0\n",
    "#             lambdas[:,i]=a\n",
    "            \n",
    "#         print(\"**********ZIP correction finished!**********\")\n",
    "\n",
    "        # # spasity矫正完之后再来一轮peak mean和library size的矫正，保证都符合实际\n",
    "        # lambdas_copy=lambdas.copy()\n",
    "        # lambdas_copy=lambdas_copy/(np.sum(lambdas_copy,axis=1).reshape(-1,1)+1e-8)*(simu_param_pm.reshape(-1,1))*lambdas_copy.shape[1]\n",
    "        # lambdas_copy=lambdas_copy/(np.sum(lambdas_copy,axis=0).reshape(1,-1)+1e-8)*(simu_param_lib.reshape(1,-1))\n",
    "\n",
    "        atac_counts=np.random.poisson(lambdas, lambdas.shape)\n",
    "        \n",
    "    elif distribution=='Bernoulli':\n",
    "        atac_counts=np.hstack(counts_list)\n",
    "        meta=np.hstack(celltype_list)\n",
    "        embeds_peak=np.hstack(embed_peak_list)\n",
    "        embeds_lib=np.hstack(embed_lib_list)\n",
    "        \n",
    "    else:\n",
    "        raise ValueError('wrong distribution input!')\n",
    "    \n",
    "    print(\"**********generate counts finshed!**********\")\n",
    "\n",
    "else:\n",
    "    raise ValueError('wrong simulation type!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08afa1eb-6c27-4569-ae95-e6f8d92258bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch2",
   "language": "python",
   "name": "pytorch2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
